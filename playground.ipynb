{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import models\n",
    "import os\n",
    "import cv2 as cv\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "DATASET_PATH = \"./data\"\n",
    "CHECKPOINT_PATH = \"saved_models\"\n",
    "TRAINING_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root=DATASET_PATH, train=True)\n",
    "data_mean = (train_dataset.data / 255.0).mean(axis=(0, 1, 2))\n",
    "data_std = (train_dataset.data / 255.0).std(axis=(0, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare transformations\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomResizedCrop((32, 32), scale=(0.8, 1.0), ratio=(0.9, 1.1)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(data_mean, data_std),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# No data augmentation for testing\n",
    "test_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(data_mean, data_std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root=DATASET_PATH, train=True,\n",
    "                                       download=True, transform=train_transform)\n",
    "\n",
    "val_dataset = torchvision.datasets.CIFAR10(root=DATASET_PATH, train=True,\n",
    "                                       download=True, transform=test_transform)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root=DATASET_PATH, train=False,\n",
    "                                       download=True, transform=test_transform)\n",
    "\n",
    "train_set, _ = torch.utils.data.random_split(train_dataset, [45000, 5000])\n",
    "_, val_set = torch.utils.data.random_split(val_dataset, [45000, 5000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True, drop_last=True, pin_memory=True, num_workers=4)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=128, shuffle=False, drop_last=False, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, drop_last=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "NUM_IMAGES = 4\n",
    "images = [train_dataset[idx][0] for idx in range(NUM_IMAGES)]\n",
    "orig_images = [Image.fromarray(train_dataset.data[idx]) for idx in range(NUM_IMAGES)]\n",
    "orig_images = [test_transform(img) for img in orig_images]\n",
    "\n",
    "img_grid = torchvision.utils.make_grid(torch.stack(images + orig_images, dim=0), nrow=4, normalize=True, pad_value=0.5)\n",
    "img_grid = img_grid.permute(1, 2, 0)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Augmentation examples on CIFAR10\")\n",
    "plt.imshow(img_grid)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_pack, labels_pack = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader, criterion):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, criterion, optimizer, train_loader, val_loader):\n",
    "    best_loss = float('inf')\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(TRAINING_EPOCHS):\n",
    "        model.train()  # Set model to training mode\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data[0], data[1]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Compute validation loss\n",
    "        val_loss = evaluate(model, val_loader, criterion)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Training Loss: {running_loss / len(train_loader)}, Validation Loss: {val_loss}\")\n",
    "\n",
    "        # Save the best model\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "    if best_model_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(\"Loaded best model with validation loss:\", best_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_model = models.LinearModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(lin_model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  (dog | cat) (cat | horse) (frog | cat) (plane | cat) (car | cat)\n"
     ]
    }
   ],
   "source": [
    "# Getting results before training\n",
    "results = lin_model(images_pack) # Example code for mini-batches from a iter object.\n",
    "\n",
    "_, predictions = torch.max(results, 1)\n",
    "print('Predicted: ', ' '.join(f'({classes[predictions[j]]} | {classes[labels_pack[j]]})'\n",
    "                              for j in range(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LM - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 1.8860215818100845, Validation Loss: 1.8377731263637542\n",
      "Epoch 2, Training Loss: 1.8114801567164582, Validation Loss: 1.798380008339882\n",
      "Epoch 3, Training Loss: 1.7950428265791674, Validation Loss: 1.7817098408937455\n",
      "Epoch 4, Training Loss: 1.7861805716131487, Validation Loss: 1.7801198691129685\n",
      "Epoch 5, Training Loss: 1.77776811673091, Validation Loss: 1.7945165514945984\n",
      "Epoch 6, Training Loss: 1.7771709926447636, Validation Loss: 1.771570059657097\n",
      "Epoch 7, Training Loss: 1.7727536302686078, Validation Loss: 1.7641219705343247\n",
      "Epoch 8, Training Loss: 1.765810692072594, Validation Loss: 1.766156366467476\n",
      "Epoch 9, Training Loss: 1.7633382835958757, Validation Loss: 1.763909450173378\n",
      "Epoch 10, Training Loss: 1.7588845117818936, Validation Loss: 1.7635781735181808\n",
      "Loaded best model with validation loss: 1.7635781735181808\n"
     ]
    }
   ],
   "source": [
    "training(lin_model, criterion, optimizer, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LM - Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lin_model.state_dict(), os.path.join(CHECKPOINT_PATH, \"linear_model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LM - Loading Trainer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_model = models.LinearModel()\n",
    "lin_model.load_state_dict(torch.load(os.path.join(CHECKPOINT_PATH, \"linear_model.pth\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LM - Getting some outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  (cat | cat) (dog | horse) (truck | cat) (cat | cat) (ship | cat) (truck | dog) (cat | cat) (frog | plane) (truck | horse) (dog | dog) (dog | bird) (ship | plane) (horse | plane) (horse | horse) (dog | cat) (plane | cat) (ship | plane) (frog | dog) (truck | cat) (car | plane)\n"
     ]
    }
   ],
   "source": [
    "# results = lin_model(images[0].unsqueeze(0)) # Example code for 1 singular image given.\n",
    "# _, prediction = torch.max(results, 1)\n",
    "# print(classes[prediction])\n",
    "\n",
    "results = lin_model(images_pack) # Example code for mini-batches from a iter object.\n",
    "\n",
    "_, predictions = torch.max(results, 1)\n",
    "print('Predicted: ', ' '.join(f'({classes[predictions[j]]} | {classes[labels_pack[j]]})'\n",
    "                              for j in range(20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP - Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = models.MLP()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(mlp_model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  (truck | cat) (truck | horse) (horse | cat) (ship | cat) (deer | cat) (deer | dog) (deer | cat) (deer | plane) (horse | horse) (ship | dog) (bird | bird) (deer | plane) (deer | plane) (deer | horse) (plane | cat) (horse | cat) (horse | plane) (truck | dog) (truck | cat) (horse | plane)\n"
     ]
    }
   ],
   "source": [
    "# Get results before training\n",
    "results = mlp_model(images_pack) # Example code for mini-batches from a iter object.\n",
    "\n",
    "_, predictions = torch.max(results, 1)\n",
    "print('Predicted: ', ' '.join(f'({classes[predictions[j]]} | {classes[labels_pack[j]]})'\n",
    "                              for j in range(20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 1.9414629036205107, Validation Loss: 1.784571608901024\n",
      "Epoch 2, Training Loss: 1.7243145154072688, Validation Loss: 1.6660382568836212\n",
      "Epoch 3, Training Loss: 1.635675970645372, Validation Loss: 1.6016606241464615\n",
      "Epoch 4, Training Loss: 1.5780114088303003, Validation Loss: 1.5510486572980882\n",
      "Epoch 5, Training Loss: 1.5357231285497335, Validation Loss: 1.507715854048729\n",
      "Epoch 6, Training Loss: 1.49422085251224, Validation Loss: 1.4754136145114898\n",
      "Epoch 7, Training Loss: 1.4646608849875948, Validation Loss: 1.4359314084053039\n",
      "Epoch 8, Training Loss: 1.434779809411095, Validation Loss: 1.4049866586923598\n",
      "Epoch 9, Training Loss: 1.411291317382769, Validation Loss: 1.383003720641136\n",
      "Epoch 10, Training Loss: 1.3906599300199765, Validation Loss: 1.3594055622816086\n",
      "Loaded best model with validation loss: 1.3594055622816086\n"
     ]
    }
   ],
   "source": [
    "training(mlp_model, criterion, optimizer, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP - Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mlp_model.state_dict(), os.path.join(CHECKPOINT_PATH, \"mlp_model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP - Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_model = models.MLP()\n",
    "mlp_model.load_state_dict(torch.load(os.path.join(CHECKPOINT_PATH, \"mlp_model.pth\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  (dog | cat) (dog | horse) (truck | cat) (horse | cat) (ship | cat) (cat | dog) (car | cat) (frog | plane) (horse | horse) (dog | dog) (truck | bird) (plane | plane) (plane | plane) (horse | horse) (dog | cat) (plane | cat) (ship | plane) (cat | dog) (truck | cat) (car | plane)\n"
     ]
    }
   ],
   "source": [
    "results = mlp_model(images_pack)\n",
    "\n",
    "_, predictions = torch.max(results, 1)\n",
    "print('Predicted: ', ' '.join(f'({classes[predictions[j]]} | {classes[labels_pack[j]]})'\n",
    "                              for j in range(20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network - Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import ConvolutionNetwork\n",
    "cnn_model = models.ConvolutionNetwork(in_chan=3, out_chan=3, kernel_size=(3, 3), stride=1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn_model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  (ship | cat) (plane | horse) (car | cat) (deer | cat) (ship | cat) (plane | dog) (ship | cat) (deer | plane) (deer | horse) (deer | dog) (deer | bird) (deer | plane) (plane | plane) (deer | horse) (deer | cat) (plane | cat) (deer | plane) (car | dog) (plane | cat) (deer | plane)\n"
     ]
    }
   ],
   "source": [
    "results = cnn_model(images_pack)\n",
    "\n",
    "_, predictions = torch.max(results, 1)\n",
    "print('Predicted: ', ' '.join(f'({classes[predictions[j]]} | {classes[labels_pack[j]]})'\n",
    "                              for j in range(20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 2.206248024589995, Validation Loss: 2.070019927620888\n",
      "Epoch 2, Training Loss: 1.9746951656124192, Validation Loss: 1.8823748052120208\n",
      "Epoch 3, Training Loss: 1.800758635895884, Validation Loss: 1.7234477251768112\n",
      "Epoch 4, Training Loss: 1.6618458857903113, Validation Loss: 1.6046024292707444\n",
      "Epoch 5, Training Loss: 1.5608153567354903, Validation Loss: 1.5649426937103272\n",
      "Epoch 6, Training Loss: 1.4966303986361904, Validation Loss: 1.4412071973085403\n",
      "Epoch 7, Training Loss: 1.4438742185250306, Validation Loss: 1.4226932913064956\n",
      "Epoch 8, Training Loss: 1.4015836311541392, Validation Loss: 1.3610921204090118\n",
      "Epoch 9, Training Loss: 1.3706441485983694, Validation Loss: 1.3281258016824722\n",
      "Epoch 10, Training Loss: 1.3383263366514462, Validation Loss: 1.3164673566818237\n",
      "Loaded best model with validation loss: 1.3164673566818237\n"
     ]
    }
   ],
   "source": [
    "training(cnn_model, criterion, optimizer, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN - Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cnn_model.state_dict(), os.path.join(CHECKPOINT_PATH, \"cnn_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  (ship | cat) (plane | horse) (car | cat) (deer | cat) (ship | cat) (plane | dog) (ship | cat) (deer | plane) (deer | horse) (deer | dog) (deer | bird) (deer | plane) (plane | plane) (deer | horse) (deer | cat) (plane | cat) (deer | plane) (car | dog) (plane | cat) (deer | plane)\n"
     ]
    }
   ],
   "source": [
    "results = cnn_model(images_pack)\n",
    "\n",
    "_, predictions = torch.max(results, 1)\n",
    "print('Predicted: ', ' '.join(f'({classes[predictions[j]]} | {classes[labels_pack[j]]})'\n",
    "                              for j in range(20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN - Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model = models.ConvolutionNetwork(in_chan=3, out_chan=3, kernel_size=(3, 3), stride=1)\n",
    "cnn_model.load_state_dict(torch.load(os.path.join(CHECKPOINT_PATH, \"cnn_model.pth\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN with Batch - Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_batch_model = models.ConvolutionBatchNetwork(3, 3, 3, 1, \"same\", 32)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn_batch_model.parameters(), 0.001, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  (ship | cat) (bird | horse) (bird | cat) (bird | cat) (ship | cat) (truck | dog) (bird | cat) (bird | plane) (bird | horse) (bird | dog) (ship | bird) (bird | plane) (ship | plane) (bird | horse) (truck | cat) (bird | cat) (ship | plane) (bird | dog) (truck | cat) (bird | plane)\n"
     ]
    }
   ],
   "source": [
    "results = cnn_batch_model(images_pack)\n",
    "\n",
    "_, predictions = torch.max(results, 1)\n",
    "print('Predicted: ', ' '.join(f'({classes[predictions[j]]} | {classes[labels_pack[j]]})'\n",
    "                              for j in range(20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN Batch - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 1.8117419467692362, Validation Loss: 1.5479045540094376\n",
      "Epoch 2, Training Loss: 1.4544453896009004, Validation Loss: 1.4148261964321136\n",
      "Epoch 3, Training Loss: 1.3409727380486296, Validation Loss: 1.3363794833421707\n",
      "Epoch 4, Training Loss: 1.2684898002874478, Validation Loss: 1.2310743629932404\n",
      "Epoch 5, Training Loss: 1.2124424313547943, Validation Loss: 1.2067373767495155\n",
      "Epoch 6, Training Loss: 1.166757396992795, Validation Loss: 1.1529369309544564\n",
      "Epoch 7, Training Loss: 1.1329047138195092, Validation Loss: 1.1011588424444199\n",
      "Epoch 8, Training Loss: 1.1010134603902486, Validation Loss: 1.1088471323251725\n",
      "Epoch 9, Training Loss: 1.0720882391997553, Validation Loss: 1.0979873314499855\n",
      "Epoch 10, Training Loss: 1.0540212538846878, Validation Loss: 1.0346444994211197\n",
      "Loaded best model with validation loss: 1.0346444994211197\n"
     ]
    }
   ],
   "source": [
    "training(cnn_batch_model, criterion, optimizer, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN Batch - Saving Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cnn_batch_model.state_dict(), os.path.join(CHECKPOINT_PATH, \"cnn_batch.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN Batch - Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_batch_model = models.ConvolutionBatchNetwork(3, 3, 3, 1)\n",
    "cnn_batch_model.load_state_dict(torch.load(os.path.join(CHECKPOINT_PATH, \"cnn_batch.pth\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  (cat | cat) (dog | horse) (truck | cat) (frog | cat) (bird | cat) (cat | dog) (car | cat) (frog | plane) (truck | horse) (horse | dog) (truck | bird) (plane | plane) (plane | plane) (deer | horse) (cat | cat) (ship | cat) (ship | plane) (cat | dog) (truck | cat) (dog | plane)\n"
     ]
    }
   ],
   "source": [
    "results = cnn_model(images_pack)\n",
    "\n",
    "_, predictions = torch.max(results, 1)\n",
    "print('Predicted: ', ' '.join(f'({classes[predictions[j]]} | {classes[labels_pack[j]]})'\n",
    "                              for j in range(20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "resnet_model = models.ResNet(3, 3, 3, 1, \"same\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet_model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  (deer | cat) (plane | horse) (deer | cat) (plane | cat) (plane | cat) (truck | dog) (deer | cat) (cat | plane) (frog | horse) (deer | dog) (deer | bird) (cat | plane) (deer | plane) (plane | horse) (dog | cat) (frog | cat) (deer | plane) (cat | dog) (frog | cat) (deer | plane)\n"
     ]
    }
   ],
   "source": [
    "results = resnet_model(images_pack)\n",
    "\n",
    "_, predictions = torch.max(results, 1)\n",
    "print('Predicted: ', ' '.join(f'({classes[predictions[j]]} | {classes[labels_pack[j]]})'\n",
    "                              for j in range(20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resnet Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 1.7070427684702425, Validation Loss: 1.506268858909607\n",
      "Epoch 2, Training Loss: 1.416259672567036, Validation Loss: 1.358312550187111\n",
      "Epoch 3, Training Loss: 1.3043836484267841, Validation Loss: 1.2852136611938476\n",
      "Epoch 4, Training Loss: 1.2372000534989556, Validation Loss: 1.2446789354085923\n",
      "Epoch 5, Training Loss: 1.187491393836475, Validation Loss: 1.1535304188728333\n",
      "Epoch 6, Training Loss: 1.1535001042222026, Validation Loss: 1.2021968349814416\n",
      "Epoch 7, Training Loss: 1.1328828667643402, Validation Loss: 1.0760079756379128\n",
      "Epoch 8, Training Loss: 1.1089296281507552, Validation Loss: 1.0623898833990097\n",
      "Epoch 9, Training Loss: 1.0911482959731011, Validation Loss: 1.1011653319001198\n",
      "Epoch 10, Training Loss: 1.0716922622800213, Validation Loss: 1.0592619195580482\n",
      "Loaded best model with validation loss: 1.0592619195580482\n"
     ]
    }
   ],
   "source": [
    "training(resnet_model, criterion, optimizer, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resnet - Saving Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet_model.state_dict(), os.path.join(CHECKPOINT_PATH, \"resnet_model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resnet - Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_model = models.ResNet(3, 3, 3, 1, \"same\")\n",
    "resnet_model.load_state_dict(torch.load(os.path.join(CHECKPOINT_PATH, \"resnet_model.pth\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  (dog | cat) (cat | horse) (plane | cat) (deer | cat) (deer | cat) (dog | dog) (car | cat) (frog | plane) (horse | horse) (dog | dog) (ship | bird) (plane | plane) (plane | plane) (horse | horse) (cat | cat) (cat | cat) (plane | plane) (cat | dog) (truck | cat) (bird | plane)\n"
     ]
    }
   ],
   "source": [
    "results = resnet_model(images_pack)\n",
    "\n",
    "_, predictions = torch.max(results, 1)\n",
    "print('Predicted: ', ' '.join(f'({classes[predictions[j]]} | {classes[labels_pack[j]]})'\n",
    "                              for j in range(20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Resnet - Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved DeepResnet with more residual connections\n"
     ]
    }
   ],
   "source": [
    "modif_res = models.ImprovedDeepResnet(3, 3, 3, 1, 1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(modif_res.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 1.5207955164787097, Validation Loss: 1.2287500262260438\n",
      "Epoch 2, Training Loss: 1.1359070291546336, Validation Loss: 1.0357946529984474\n",
      "Epoch 3, Training Loss: 0.9860472556872245, Validation Loss: 0.967532454431057\n",
      "Epoch 4, Training Loss: 0.8902461751234158, Validation Loss: 0.8864286795258522\n",
      "Epoch 5, Training Loss: 0.823314256817527, Validation Loss: 0.8262899577617645\n",
      "Epoch 6, Training Loss: 0.767208820394641, Validation Loss: 0.7172391235828399\n",
      "Epoch 7, Training Loss: 0.7248924921380828, Validation Loss: 0.6558450162410736\n",
      "Epoch 8, Training Loss: 0.681319013025686, Validation Loss: 0.6308825209736824\n",
      "Epoch 9, Training Loss: 0.6514426451123339, Validation Loss: 0.6829239532351494\n",
      "Epoch 10, Training Loss: 0.623323005488795, Validation Loss: 0.5494961895048618\n",
      "Loaded best model with validation loss: 0.5494961895048618\n"
     ]
    }
   ],
   "source": [
    "training(modif_res, criterion, optimizer, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  (horse | cat) (dog | horse) (horse | cat) (car | cat) (horse | cat) (horse | dog) (horse | cat) (bird | plane) (frog | horse) (horse | dog) (bird | bird) (horse | plane) (frog | plane) (horse | horse) (bird | cat) (horse | cat) (car | plane) (frog | dog) (horse | cat) (bird | plane)\n"
     ]
    }
   ],
   "source": [
    "results = modif_res(images_pack)\n",
    "\n",
    "_, predictions = torch.max(results, 1)\n",
    "print('Predicted: ', ' '.join(f'({classes[predictions[j]]} | {classes[labels_pack[j]]})'\n",
    "                              for j in range(20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(modif_res.state_dict(), os.path.join(CHECKPOINT_PATH, \"modif_res.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Resnet - Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modif_res.load_state_dict(torch.load(os.path.join(CHECKPOINT_PATH, \"modif_res.pth\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep CNN - Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "modif_cnn = models.ModifiedDeepCNN(3, 3, 3, 1, 1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(modif_cnn.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 1.529681740323363, Validation Loss: 1.3269953787326814\n",
      "Epoch 2, Training Loss: 1.1339651684136132, Validation Loss: 1.0025365203619003\n",
      "Epoch 3, Training Loss: 0.9788326921626034, Validation Loss: 0.8879674136638641\n",
      "Epoch 4, Training Loss: 0.8786105780180363, Validation Loss: 0.7911751374602318\n",
      "Epoch 5, Training Loss: 0.8049800985219472, Validation Loss: 0.7753568172454834\n",
      "Epoch 6, Training Loss: 0.75024736606837, Validation Loss: 0.6604995280504227\n",
      "Epoch 7, Training Loss: 0.7057675135950757, Validation Loss: 0.6441932961344718\n",
      "Epoch 8, Training Loss: 0.6638007952786579, Validation Loss: 0.7074058540165424\n",
      "Epoch 9, Training Loss: 0.6331077915990454, Validation Loss: 0.6378682434558869\n",
      "Epoch 10, Training Loss: 0.6072842893097815, Validation Loss: 0.5464334525167942\n",
      "Loaded best model with validation loss: 0.5464334525167942\n"
     ]
    }
   ],
   "source": [
    "training(modif_cnn, criterion, optimizer, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  (horse | cat) (truck | horse) (truck | cat) (frog | cat) (frog | cat) (frog | dog) (plane | cat) (truck | plane) (horse | horse) (cat | dog) (plane | bird) (horse | plane) (truck | plane) (frog | horse) (frog | cat) (horse | cat) (frog | plane) (plane | dog) (horse | cat) (truck | plane)\n"
     ]
    }
   ],
   "source": [
    "results = modif_cnn(images_pack)\n",
    "\n",
    "_, predictions = torch.max(results, 1)\n",
    "print('Predicted: ', ' '.join(f'({classes[predictions[j]]} | {classes[labels_pack[j]]})'\n",
    "                              for j in range(20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(modif_cnn.state_dict(), os.path.join(CHECKPOINT_PATH, \"modif_cnn.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep CNN - Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modif_cnn.load_state_dict(torch.load(os.path.join(CHECKPOINT_PATH, \"modif_cnn.pth\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STL10 - Initialization (Testing Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "DATASET_PATH_STL = \"./data/stl10\"\n",
    "\n",
    "# Define STL-10 transformations (resize + normalize like CIFAR-10)\n",
    "transform_stl = transforms.Compose([\n",
    "    transforms.Resize((32, 32)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  \n",
    "])\n",
    "\n",
    "# Load STL-10 test dataset\n",
    "stl10_testset = torchvision.datasets.STL10(\n",
    "    root=DATASET_PATH_STL, split=\"test\", download=True, transform=transform_stl\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STL-10 Test Dataset Size: 8000\n"
     ]
    }
   ],
   "source": [
    "# Create test DataLoader (same batch size, num_workers as CIFAR-10)\n",
    "test_loader_stl = DataLoader(\n",
    "    stl10_testset, batch_size=128, shuffle=False, drop_last=False, num_workers=4\n",
    ")\n",
    "\n",
    "# Check dataset size\n",
    "print(f\"STL-10 Test Dataset Size: {len(stl10_testset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_acc(model_type, data_test_loader):\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    model_type.eval()\n",
    "\n",
    "    # Ensure computations do not track gradients\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model_type.to(device)  # Move model to the same device as test data\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for data in data_test_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)  # Move to same device\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model_type(images)\n",
    "            _, predicted = torch.max(outputs, 1)  # Get class with highest score\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    # model_type.__class__.__name__ to get model name\n",
    "    print(f'Accuracy of the network on the {len(data_test_loader.dataset)} test images ({model_type.__class__.__name__}): {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy CIFAR-10 - 10 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lin Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images (LinearModel): 40.13%\n"
     ]
    }
   ],
   "source": [
    "model_acc(lin_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images (MLP): 52.31%\n"
     ]
    }
   ],
   "source": [
    "model_acc(mlp_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images (ConvolutionNetwork): 53.55%\n"
     ]
    }
   ],
   "source": [
    "model_acc(cnn_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN With Batch Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images (ConvolutionBatchNetwork): 64.93%\n"
     ]
    }
   ],
   "source": [
    "model_acc(cnn_batch_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images (ResNet): 64.86%\n"
     ]
    }
   ],
   "source": [
    "model_acc(resnet_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep CNN Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images (ModifiedDeepCNN): 78.78%\n"
     ]
    }
   ],
   "source": [
    "model_acc(modif_cnn, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Resnet Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images (ImprovedDeepResnet): 78.49%\n"
     ]
    }
   ],
   "source": [
    "model_acc(modif_res, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10 - 20 Epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading 20 Epoch Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 20 Epoch Checkpoint\n",
    "CHECKPOINT_PATH_20_EPOCHS = \"saved_models_20E\"\n",
    "\n",
    "# Linear\n",
    "lin_model_20 = models.LinearModel()\n",
    "lin_model_20.load_state_dict(torch.load(os.path.join(CHECKPOINT_PATH_20_EPOCHS, \"linear_model.pth\")))\n",
    "\n",
    "# MLP\n",
    "mlp_model_20 = models.MLP()\n",
    "mlp_model_20.load_state_dict(torch.load(os.path.join(CHECKPOINT_PATH_20_EPOCHS, \"mlp_model.pth\")))\n",
    "\n",
    "# CNN\n",
    "cnn_model_20 = models.ConvolutionNetwork(in_chan=3, out_chan=3, kernel_size=(3, 3), stride=1)\n",
    "cnn_model_20.load_state_dict(torch.load(os.path.join(CHECKPOINT_PATH_20_EPOCHS, \"cnn_model.pth\")))\n",
    "\n",
    "# CNN Batch\n",
    "cnn_batch_model_20 = models.ConvolutionBatchNetwork(3, 3, 3, 1)\n",
    "cnn_batch_model_20.load_state_dict(torch.load(os.path.join(CHECKPOINT_PATH_20_EPOCHS, \"cnn_batch.pth\")))\n",
    "\n",
    "# Resnet\n",
    "resnet_model_20 = models.ResNet(3, 3, 3, 1, \"same\")\n",
    "resnet_model_20.load_state_dict(torch.load(os.path.join(CHECKPOINT_PATH_20_EPOCHS, \"resnet_model.pth\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy 20 Epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lin Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images (LinearModel): 40.10%\n"
     ]
    }
   ],
   "source": [
    "model_acc(lin_model_20, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images (MLP): 56.22%\n"
     ]
    }
   ],
   "source": [
    "model_acc(mlp_model_20, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images (ConvolutionNetwork): 62.49%\n"
     ]
    }
   ],
   "source": [
    "model_acc(cnn_model_20, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN With Batch Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images (ConvolutionBatchNetwork): 67.57%\n"
     ]
    }
   ],
   "source": [
    "model_acc(cnn_batch_model_20, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images (ResNet): 66.75%\n"
     ]
    }
   ],
   "source": [
    "model_acc(resnet_model_20, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy For Each Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_wise_acc(model_type, data_test_loader, dataset='cifar10'):\n",
    "\n",
    "    cifar10_classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    \n",
    "    \n",
    "    stl10_classes = ['plane', 'bird', 'car', 'cat', 'deer', 'dog', 'horse', 'monkey', 'ship', 'truck']\n",
    "    \n",
    "    if dataset.lower() == 'stl10':\n",
    "        classes = stl10_classes\n",
    "    else:\n",
    "        classes = cifar10_classes\n",
    "\n",
    "    # prepare to count predictions for each class\n",
    "    correct_pred = {classname: 0 for classname in classes}\n",
    "    total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "    # again no gradients needed\n",
    "    with torch.no_grad():\n",
    "        for data in data_test_loader:\n",
    "            images, labels = data\n",
    "            outputs = model_type(images)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            # collect the correct predictions for each class\n",
    "            for label, prediction in zip(labels, predictions):\n",
    "                if label == prediction:\n",
    "                    correct_pred[classes[label]] += 1\n",
    "                total_pred[classes[label]] += 1\n",
    "\n",
    "    print(f\"{model_type.__class__.__name__}:\\n\")\n",
    "\n",
    "    # print accuracy for each class\n",
    "    for classname, correct_count in correct_pred.items():\n",
    "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "        print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classwise Accuracy for 10 Epochs - CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearModel:\n",
      "\n",
      "Accuracy for class: plane is 41.5 %\n",
      "Accuracy for class: car   is 43.6 %\n",
      "Accuracy for class: bird  is 28.1 %\n",
      "Accuracy for class: cat   is 27.2 %\n",
      "Accuracy for class: deer  is 31.6 %\n",
      "Accuracy for class: dog   is 30.7 %\n",
      "Accuracy for class: frog  is 47.2 %\n",
      "Accuracy for class: horse is 43.8 %\n",
      "Accuracy for class: ship  is 59.4 %\n",
      "Accuracy for class: truck is 48.2 %\n"
     ]
    }
   ],
   "source": [
    "class_wise_acc(lin_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP:\n",
      "\n",
      "Accuracy for class: plane is 55.1 %\n",
      "Accuracy for class: car   is 69.5 %\n",
      "Accuracy for class: bird  is 39.7 %\n",
      "Accuracy for class: cat   is 32.7 %\n",
      "Accuracy for class: deer  is 39.8 %\n",
      "Accuracy for class: dog   is 38.9 %\n",
      "Accuracy for class: frog  is 62.8 %\n",
      "Accuracy for class: horse is 59.8 %\n",
      "Accuracy for class: ship  is 67.2 %\n",
      "Accuracy for class: truck is 57.6 %\n"
     ]
    }
   ],
   "source": [
    "class_wise_acc(mlp_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvolutionNetwork:\n",
      "\n",
      "Accuracy for class: plane is 61.0 %\n",
      "Accuracy for class: car   is 73.2 %\n",
      "Accuracy for class: bird  is 27.7 %\n",
      "Accuracy for class: cat   is 30.1 %\n",
      "Accuracy for class: deer  is 38.3 %\n",
      "Accuracy for class: dog   is 47.0 %\n",
      "Accuracy for class: frog  is 69.3 %\n",
      "Accuracy for class: horse is 64.1 %\n",
      "Accuracy for class: ship  is 59.2 %\n",
      "Accuracy for class: truck is 65.6 %\n"
     ]
    }
   ],
   "source": [
    "class_wise_acc(cnn_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvolutionBatchNetwork:\n",
      "\n",
      "Accuracy for class: plane is 68.0 %\n",
      "Accuracy for class: car   is 82.2 %\n",
      "Accuracy for class: bird  is 46.4 %\n",
      "Accuracy for class: cat   is 34.2 %\n",
      "Accuracy for class: deer  is 52.2 %\n",
      "Accuracy for class: dog   is 64.4 %\n",
      "Accuracy for class: frog  is 76.0 %\n",
      "Accuracy for class: horse is 75.8 %\n",
      "Accuracy for class: ship  is 78.8 %\n",
      "Accuracy for class: truck is 68.8 %\n"
     ]
    }
   ],
   "source": [
    "class_wise_acc(cnn_batch_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet:\n",
      "\n",
      "Accuracy for class: plane is 68.0 %\n",
      "Accuracy for class: car   is 79.7 %\n",
      "Accuracy for class: bird  is 50.8 %\n",
      "Accuracy for class: cat   is 38.5 %\n",
      "Accuracy for class: deer  is 56.5 %\n",
      "Accuracy for class: dog   is 54.4 %\n",
      "Accuracy for class: frog  is 80.3 %\n",
      "Accuracy for class: horse is 70.9 %\n",
      "Accuracy for class: ship  is 80.0 %\n",
      "Accuracy for class: truck is 67.1 %\n"
     ]
    }
   ],
   "source": [
    "class_wise_acc(resnet_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModifiedDeepCNN:\n",
      "\n",
      "Accuracy for class: plane is 82.4 %\n",
      "Accuracy for class: car   is 86.6 %\n",
      "Accuracy for class: bird  is 66.0 %\n",
      "Accuracy for class: cat   is 62.5 %\n",
      "Accuracy for class: deer  is 77.2 %\n",
      "Accuracy for class: dog   is 66.0 %\n",
      "Accuracy for class: frog  is 86.5 %\n",
      "Accuracy for class: horse is 77.2 %\n",
      "Accuracy for class: ship  is 89.2 %\n",
      "Accuracy for class: truck is 86.1 %\n"
     ]
    }
   ],
   "source": [
    "class_wise_acc(modif_cnn, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImprovedDeepResnet:\n",
      "\n",
      "Accuracy for class: plane is 77.2 %\n",
      "Accuracy for class: car   is 91.2 %\n",
      "Accuracy for class: bird  is 69.4 %\n",
      "Accuracy for class: cat   is 60.2 %\n",
      "Accuracy for class: deer  is 69.9 %\n",
      "Accuracy for class: dog   is 73.3 %\n",
      "Accuracy for class: frog  is 84.7 %\n",
      "Accuracy for class: horse is 82.8 %\n",
      "Accuracy for class: ship  is 87.8 %\n",
      "Accuracy for class: truck is 81.3 %\n"
     ]
    }
   ],
   "source": [
    "class_wise_acc(modif_res, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classwise Accuracy for 20 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearModel:\n",
      "\n",
      "Accuracy for class: plane is 53.5 %\n",
      "Accuracy for class: car   is 43.9 %\n",
      "Accuracy for class: bird  is 23.5 %\n",
      "Accuracy for class: cat   is 23.4 %\n",
      "Accuracy for class: deer  is 33.4 %\n",
      "Accuracy for class: dog   is 31.8 %\n",
      "Accuracy for class: frog  is 47.5 %\n",
      "Accuracy for class: horse is 41.1 %\n",
      "Accuracy for class: ship  is 59.2 %\n",
      "Accuracy for class: truck is 43.7 %\n"
     ]
    }
   ],
   "source": [
    "class_wise_acc(lin_model_20, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP:\n",
      "\n",
      "Accuracy for class: plane is 62.6 %\n",
      "Accuracy for class: car   is 64.2 %\n",
      "Accuracy for class: bird  is 45.3 %\n",
      "Accuracy for class: cat   is 31.5 %\n",
      "Accuracy for class: deer  is 49.0 %\n",
      "Accuracy for class: dog   is 46.8 %\n",
      "Accuracy for class: frog  is 67.0 %\n",
      "Accuracy for class: horse is 64.2 %\n",
      "Accuracy for class: ship  is 64.4 %\n",
      "Accuracy for class: truck is 67.2 %\n"
     ]
    }
   ],
   "source": [
    "class_wise_acc(mlp_model_20, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvolutionNetwork:\n",
      "\n",
      "Accuracy for class: plane is 68.0 %\n",
      "Accuracy for class: car   is 76.8 %\n",
      "Accuracy for class: bird  is 37.8 %\n",
      "Accuracy for class: cat   is 32.1 %\n",
      "Accuracy for class: deer  is 45.1 %\n",
      "Accuracy for class: dog   is 59.2 %\n",
      "Accuracy for class: frog  is 75.1 %\n",
      "Accuracy for class: horse is 75.4 %\n",
      "Accuracy for class: ship  is 78.5 %\n",
      "Accuracy for class: truck is 76.9 %\n"
     ]
    }
   ],
   "source": [
    "class_wise_acc(cnn_model_20, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvolutionBatchNetwork:\n",
      "\n",
      "Accuracy for class: plane is 75.9 %\n",
      "Accuracy for class: car   is 86.1 %\n",
      "Accuracy for class: bird  is 47.3 %\n",
      "Accuracy for class: cat   is 37.9 %\n",
      "Accuracy for class: deer  is 51.1 %\n",
      "Accuracy for class: dog   is 58.0 %\n",
      "Accuracy for class: frog  is 90.0 %\n",
      "Accuracy for class: horse is 82.8 %\n",
      "Accuracy for class: ship  is 72.1 %\n",
      "Accuracy for class: truck is 74.5 %\n"
     ]
    }
   ],
   "source": [
    "class_wise_acc(cnn_batch_model_20, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet:\n",
      "\n",
      "Accuracy for class: plane is 73.3 %\n",
      "Accuracy for class: car   is 82.5 %\n",
      "Accuracy for class: bird  is 49.2 %\n",
      "Accuracy for class: cat   is 27.8 %\n",
      "Accuracy for class: deer  is 63.5 %\n",
      "Accuracy for class: dog   is 56.1 %\n",
      "Accuracy for class: frog  is 88.6 %\n",
      "Accuracy for class: horse is 74.2 %\n",
      "Accuracy for class: ship  is 82.6 %\n",
      "Accuracy for class: truck is 69.7 %\n"
     ]
    }
   ],
   "source": [
    "class_wise_acc(resnet_model_20, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy STL10 - 10 Epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lin Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 8000 test images (LinearModel): 18.41%\n"
     ]
    }
   ],
   "source": [
    "model_acc(lin_model, test_loader_stl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 8000 test images (MLP): 20.96%\n"
     ]
    }
   ],
   "source": [
    "model_acc(mlp_model, test_loader_stl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 8000 test images (ConvolutionNetwork): 18.01%\n"
     ]
    }
   ],
   "source": [
    "model_acc(cnn_model, test_loader_stl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN With Batch Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 8000 test images (ConvolutionBatchNetwork): 22.98%\n"
     ]
    }
   ],
   "source": [
    "model_acc(cnn_batch_model, test_loader_stl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 8000 test images (ResNet): 21.60%\n"
     ]
    }
   ],
   "source": [
    "model_acc(resnet_model, test_loader_stl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep CNN Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 8000 test images (ModifiedDeepCNN): 26.30%\n"
     ]
    }
   ],
   "source": [
    "model_acc(modif_cnn, test_loader_stl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Resnet Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 8000 test images (ImprovedDeepResnet): 28.34%\n"
     ]
    }
   ],
   "source": [
    "model_acc(modif_res, test_loader_stl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy For Each Class - STL10 - 10 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearModel:\n",
      "\n",
      "Accuracy for class: plane is 30.0 %\n",
      "Accuracy for class: bird  is 2.0 %\n",
      "Accuracy for class: car   is 31.2 %\n",
      "Accuracy for class: cat   is 30.1 %\n",
      "Accuracy for class: deer  is 29.6 %\n",
      "Accuracy for class: dog   is 13.9 %\n",
      "Accuracy for class: horse is 11.8 %\n",
      "Accuracy for class: monkey is 2.4 %\n",
      "Accuracy for class: ship  is 21.9 %\n",
      "Accuracy for class: truck is 11.2 %\n"
     ]
    }
   ],
   "source": [
    "class_wise_acc(lin_model, test_loader_stl, \"stl10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP:\n",
      "\n",
      "Accuracy for class: plane is 42.6 %\n",
      "Accuracy for class: bird  is 1.0 %\n",
      "Accuracy for class: car   is 12.1 %\n",
      "Accuracy for class: cat   is 9.2 %\n",
      "Accuracy for class: deer  is 53.6 %\n",
      "Accuracy for class: dog   is 13.4 %\n",
      "Accuracy for class: horse is 15.2 %\n",
      "Accuracy for class: monkey is 4.8 %\n",
      "Accuracy for class: ship  is 46.4 %\n",
      "Accuracy for class: truck is 11.2 %\n"
     ]
    }
   ],
   "source": [
    "class_wise_acc(mlp_model, test_loader_stl, \"stl10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvolutionNetwork:\n",
      "\n",
      "Accuracy for class: plane is 35.9 %\n",
      "Accuracy for class: bird  is 0.0 %\n",
      "Accuracy for class: car   is 15.0 %\n",
      "Accuracy for class: cat   is 3.6 %\n",
      "Accuracy for class: deer  is 73.5 %\n",
      "Accuracy for class: dog   is 5.5 %\n",
      "Accuracy for class: horse is 13.2 %\n",
      "Accuracy for class: monkey is 2.5 %\n",
      "Accuracy for class: ship  is 25.6 %\n",
      "Accuracy for class: truck is 5.2 %\n"
     ]
    }
   ],
   "source": [
    "class_wise_acc(cnn_model, test_loader_stl, \"stl10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvolutionBatchNetwork:\n",
      "\n",
      "Accuracy for class: plane is 51.6 %\n",
      "Accuracy for class: bird  is 0.0 %\n",
      "Accuracy for class: car   is 30.6 %\n",
      "Accuracy for class: cat   is 10.8 %\n",
      "Accuracy for class: deer  is 65.0 %\n",
      "Accuracy for class: dog   is 10.9 %\n",
      "Accuracy for class: horse is 1.0 %\n",
      "Accuracy for class: monkey is 0.5 %\n",
      "Accuracy for class: ship  is 54.2 %\n",
      "Accuracy for class: truck is 5.1 %\n"
     ]
    }
   ],
   "source": [
    "class_wise_acc(cnn_batch_model, test_loader_stl, \"stl10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet:\n",
      "\n",
      "Accuracy for class: plane is 49.8 %\n",
      "Accuracy for class: bird  is 0.0 %\n",
      "Accuracy for class: car   is 18.6 %\n",
      "Accuracy for class: cat   is 8.5 %\n",
      "Accuracy for class: deer  is 74.1 %\n",
      "Accuracy for class: dog   is 6.5 %\n",
      "Accuracy for class: horse is 1.1 %\n",
      "Accuracy for class: monkey is 0.9 %\n",
      "Accuracy for class: ship  is 51.6 %\n",
      "Accuracy for class: truck is 4.9 %\n"
     ]
    }
   ],
   "source": [
    "class_wise_acc(resnet_model, test_loader_stl, \"stl10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModifiedDeepCNN:\n",
      "\n",
      "Accuracy for class: plane is 55.4 %\n",
      "Accuracy for class: bird  is 0.0 %\n",
      "Accuracy for class: car   is 12.6 %\n",
      "Accuracy for class: cat   is 23.4 %\n",
      "Accuracy for class: deer  is 86.8 %\n",
      "Accuracy for class: dog   is 5.2 %\n",
      "Accuracy for class: horse is 2.4 %\n",
      "Accuracy for class: monkey is 0.4 %\n",
      "Accuracy for class: ship  is 64.0 %\n",
      "Accuracy for class: truck is 12.9 %\n"
     ]
    }
   ],
   "source": [
    "class_wise_acc(modif_cnn, test_loader_stl, \"stl10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImprovedDeepResnet:\n",
      "\n",
      "Accuracy for class: plane is 61.2 %\n",
      "Accuracy for class: bird  is 0.0 %\n",
      "Accuracy for class: car   is 13.1 %\n",
      "Accuracy for class: cat   is 19.6 %\n",
      "Accuracy for class: deer  is 81.2 %\n",
      "Accuracy for class: dog   is 15.1 %\n",
      "Accuracy for class: horse is 4.5 %\n",
      "Accuracy for class: monkey is 0.2 %\n",
      "Accuracy for class: ship  is 62.9 %\n",
      "Accuracy for class: truck is 25.4 %\n"
     ]
    }
   ],
   "source": [
    "class_wise_acc(modif_res, test_loader_stl, \"stl10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
